%----------------------------------------------------------------------------------------
% Packages & config %----------------------------------------------------------------------------------------

\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{cmap}
\usepackage{graphicx} 
\usepackage{bmpsize}

%\usepackage{multicol}
%\usepackage[margin=2cm]{geometry}
%----------------------------------------------------------------------------------------
%	Infos du doc
%----------------------------------------------------------------------------------------

\title{Recherche d'information : diversité} 
\date{Janvier 2018} 
\author{
   Loïc Herbelot
   \and
   Sébastien Pereira
  } 



\begin{document}

\maketitle 


\tableofcontents{}

\abstract{
Nous nous sommes intéressés au problème de la diversité des résultats renvoyés par un système de recherche d'informations. Nous avons implémenté plusieurs algorithmes célèbres que nous avons testés sur un benchmark \textsc{easyCLEF08}. Ces algorithmes nous ont permis d'améliorer la diversité des résultats renvoyés.}



\section{Introduction}

\paragraph{Problématique}

On évalue d'ordinaire les performances des systèmes de recherche d'information (SRI) avec des mesures telles que la précision ou le rappel. Ces métriques dénombrent les résultats pertinents renvoyés pour une requête. L'inconvénient majeur de ces méthodes d'évaluation est qu'elles considèrent seulement le nombre des documents pertinents renvoyés et donc ne tiennent compte de l'aspect redondant des documents renvoyés. 

\paragraph{Intérêt de la diversité}
Si par exemple un utilisateur veut voir des photos du Machu Picchu, il est sans doute intéressant de lui renvoyer des photos avec différentes prises de vue, différentes conditions météorologiques, etc. Ce raisonnement se généralise à tout type de requête dans les SRI, d'où l'intérêt de résoudre ce problème.
\paragraph{Difficultés}
Il est difficile de maximiser à la fois la diversité et la précision d'un SRI. En effet en essayant de diversifier les résultats renvoyés pour une requête, un SRI renverra moins de documents pertinents, d'où une baisse de précision.

\paragraph{Méthode de résolution}
Afin de maximiser la diversité de notre SRI, nous utilisons deux méthodes différentes.

Premièrement nous effectuerons un \textit{clustering post-retrieval}, qui consiste à trouver des groupes au sein d'une liste de documents, pour pouvoir diversifier notre réponse à une requête.

Deuxièmement nous utiliserons des métriques qui permettront de renvoyer des documents "nouveaux" en réponse à une question, avec un algorithme glouton

\paragraph{Plan}
Nous allons dans un premier temps faire un état de l'art des méthodes utilisées pour répondre à la problématique. Ensuite nous ferons des hypothèses afin de proposer une démarche expérimentale visant à mettre en œuvre des techniques utilisées dans la littérature. Nous évaluerons nos algorithmes sur un benchmark \textsc{easyCLEF08} que nous comparerons à une baseline. Pour finir nous conclurons quant à nos expériences.

\section{État de l'art}
Dans la littérature il existe principalement deux manières de résoudre le problème de la diversité.\\

\paragraph{Algorithme à base de partitionnement}
La première méthode se base sur des algorithmes de \textit{clustering}. Elle optimise à la fois la pertinence et la diversité car elle fait deux hypothèses fondamentales. 

La première hypothèse est que si un document est pertinent alors les documents se trouvant dans le même cluster ont également de plus grandes chances d'être pertinent que des documents qui ne s'y trouvent pas. 

La deuxième hypothèse tient au fait que le découpage en clusters représente les différents sous-thèmes qui peuvent exister pour une requête.

En pratique on effectue ce qu'on appelle un \textit{clustering post retrieval}. C'est-à-dire qu'on utilise une méthode pour récupérer la liste des documents qui pourraient correspondre à une requête (par exemple "photos du Machu Picchu"), puis on essaie d'organiser cette liste en groupes (\textit{clusters}) qui correspondraient à des sous-thèmes (les photos de nuit, les photos aériennes, etc.). Finalement on renvoie les résultats en piochant dans ces groupes, pour avoir une réponse diversifiée à la requête.

Cette méthode optimise en même temps la pertinence et la diversité, cependant il existe beaucoup de paramètres à trouver pour avoir un SRI optimal.



\paragraph{Algorithme glouton}
Cette deuxième méthode suit le principe des algorithmes gloutons. Pour une requête, l'algorithme va choisir successivement les documents qui semblent le plus adapté en fonction des documents que l'algorithme a déjà choisi.

Par exemple si on veut une photo du Machu Picchu, l'algorithme va sélectionner une photo qui colle à la requête, comme une photo aérienne. Puis il va sélectionner une deuxième photo qui colle à la requête, mais qui ne ressemble pas à la première photo renvoyée, comme une photo nocturne. Puis l'algorithme continue à piocher les résultats "originaux" pour renvoyer une liste diversifiée de documents.

\section{Proposition}

Nous faisons l'hypothèse qu'un utilisateur va regarder au maximum 40 photos lorsqu'il effectue une recherche 

\begin{figure}[H]
\caption{1ère page de résultats, la ligne rouge délimite 40 résultats}
\centering
\includegraphics[width=13cm]{40_images.png}
\end{figure}

\subsection{Clustering post-retrieval}
\paragraph{K-Means}

Dans un premier temps nous allons développer une solution basée sur des méthodes de partitionnement. Notre méthode récupère une première sélection de documents qui peuvent répondre à une requête grâce à un modèle simple. Ici nous utilisons un modèle vectoriel qui associe à chaque mot son score \textit{tf-idf}. Dans ce modèle un document est proche d'une requête s'ils contiennent les mêmes mots, notamment s'ils contiennent des mots qui apparaissent peu ailleurs.

Ensuite notre SRI réalisera un clustering des premiers documents renvoyés par notre modèle. Nous utilisons ici l'algorithme des k-moyennes. Nous faisons varier le nombre de clusters pour trouver le meilleur partitionnement, on propose d'évaluer la qualité de notre partitionnement grâce au coefficient silhouette \cite{rousseeuw87}. 
Nous avons choisi de conserver seulement les 200 premiers documents renvoyés par le modèle de base pour effectuer notre partitionnement car cela réalisait un bon compromis entre pertinence des résultats et rapidité de la réponse, pour avoir 40 résultats.

Finalement notre SRI trie les clusters selon leur proximité à la requête, et il trie les documents dans les clusters selon leur proximité à la requête. Le SRI renvoie les documents en alternant parmi les différents clusters. 

Nous allons ensuite essayer de confirmer ou d'infirmer ces choix lors de notre démarche expérimentale pour voir si notre heuristique est performante. 

\paragraph{MeanShift}
Nous utilisons un autre algorithme de clustering, MeanShift \cite{fukunuga75}, plus adapté que K-Means à notre problème.
Cet algorithme permet de partitionner un ensemble de points sans qu'on spécifie le nombre de clusters voulus, MeanShift trouve le nombre optimal de groupes.

Ainsi notre SRI effectue les mêmes étapes que pour K-Means, cependant il ne teste pas différents clusterings, ce qui accroît sa vitesse.


\subsection{Algorithme glouton} Nous allons ensuite envisager une résolution du problème de diversité en utilisant une méthode de type "glouton" \cite{zhai03}. \\

Le but de cette méthode est de maximiser la nouveauté des résultats renvoyés. En pratique on incrémente une liste de documents à renvoyer, puis à chaque itération on va chercher à renvoyer le document qui maximise la nouveauté par rapport aux documents déjà présents dans la liste.

Plus formellement on a l'algorithme suivant:

\begin{algorithm}
\caption{Algorithme glouton}
\begin{algorithmic}
\REQUIRE $U$ un ensemble de documents non-ordonnés
\REQUIRE $K$ le nombre de documents à ordonner
\REQUIRE $q$ une requête
\FOR {$i=1,2,\dots,K$} 
\STATE $d_i \leftarrow \arg\max_{d_u \in U} value(d_u;q, d_1,d_2,\dots,d_{i-1})$ 
\STATE $U \leftarrow U \backslash \left\{d_i\right\}$
\ENDFOR
\RETURN Les documents dans l'ordre $\left\{d_1, d_2,\dots, d_K\right\}$
\end{algorithmic}
\end{algorithm}

Les avantages de cet algorithme sont sa simplicité, sa potentielle rapidité car l'algorithme obtient un classement document par document, et sa flexibilité, car il est facile de changer la fonction $value$ qui est le cœur de l'algorithme. Cependant comme beaucoup d'heuristique cette méthode peut facilement trouver un optimum local plutôt qu'un optimum global.


On utilisera comme fonction $value$ la \textit{Maximal Marginal Relevance} : 
$$value_{MMR}(d_u;q,d_1,...,d_{i-1}) = \underbrace{\alpha Sim_{1}(d_u,q)}_{\text{pertinence}} - \underbrace{(1-\alpha)\max\limits_{j < i} Sim_{2}(d_u, d_j)}_{\text{divserité}}$$

Où :\\
$Sim_{1}$ et $Sim_{2}$ sont des mesures de similarités classiques, par exemple la similarité cosine (un document et une requête sont représentés par un vecteur tf-idf de termes).

\newpage
\section{Expérimentations}
\paragraph{Présentation des données easyCLEF08}

\paragraph{Présentation des mesures d'évaluation}

\paragraph{Résultats}
Parler de la baseline
[Ne pas oublier d'étudier les paramètres]

\section{Conclusion}

[Perspectives et ouvertures]
\cite{lamport94}

\begin{thebibliography}{9}
\bibitem{rousseeuw87}
\textit{Silhouettes: A graphical aid to the interpretation and validation of cluster analysis},
Peter J.Rousseeuw

\bibitem{fukunuga75}
\textit{The Estimation of the Gradient of a Density Function, with Applications in Pattern Recognition}, Fukunaga, Keinosuke, Hostetler

\bibitem{zhai03}
\textit{Beyond Independent Relevance: Methods and EvaluationMetrics for Subtopic Retrieval}, Zhai, Cohen, Lafferty

\end{thebibliography}


\end{document}